{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dh610/ai-intensive2/blob/main/lab3/lab3_Word%20Embedding_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/ai-intensive2\n",
        "!git pull\n",
        "%cd lab3"
      ],
      "metadata": {
        "id": "ByW_BcR8EsYI",
        "outputId": "d4f0c6a6-fa65-48ea-900b-abfec215a517",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/ai-intensive2\n",
            "Already up to date.\n",
            "/content/drive/MyDrive/ai-intensive2/lab3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6HfJq3sEqa-"
      },
      "source": [
        "# Lab 3 : Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Mdp70JEqbC"
      },
      "source": [
        "@copyright:\n",
        "    (c) 2023. iKnow Lab. Ajou Univ., All rights reserved.\n",
        "\n",
        "M.S. Student: Wansik-Jo (jws5327@ajou.ac.kr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKMgP8cLEqbD"
      },
      "source": [
        "# For assignment\n",
        "\n",
        "- Python code의 주석 처리되어있는 부분을 구현하면 됩니다.\n",
        "- MD 형식의 Cell의 [BLANK] 부분을 채우면 됩니다.\n",
        "- MD 형식의 Cell의 [ANSWER] 부분 이후에 답을 작성하면 됩니다.\n",
        "- 조교에게 퀴즈의 답과 함께 코드 실행 결과를 보여준 뒤, BB에 제출 후 가시면 됩니다.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMWkTo3pEqbH"
      },
      "source": [
        "\n",
        "## 목차\n",
        "\n",
        "1. Word Embeddings (Introduction)\n",
        "    - Word2vec\n",
        "    - Predict Capital of Country\n",
        "    - PCA\n",
        "2. CBOW vs Skip-gram\n",
        "    - CBOW\n",
        "    - Implementation from Scratch\n",
        "    - Skip-gram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-i4MUt0EqbI"
      },
      "source": [
        "## 1. Word Embeddings (Introduction)\n",
        "\n",
        "### 1.1 google word2vec\n",
        "\n",
        "- word2vec은 2013년 구글 연구팀이 발표한 논문으로, 단어를 벡터로 표현하는 방법론이다.\n",
        "- word2vec은 CBOW와 Skip-gram 두 가지 방법론을 제시한다.\n",
        "\n",
        "- [CBOW]는 주변 단어들을 이용해 중심 단어를 예측하는 방법론이다.\n",
        "- [Skip-gram]은 중심 단어를 이용해 주변 단어들을 예측하는 방법론이다.\n",
        "\n",
        "해당 실습에서는, 학습된 word2vec 모델을 이용해 word vector를 얻어보고, 이를 이용해 단어 간 관계를 분석한다.\n",
        "\n",
        "<details>\n",
        "<summary>Reference</summary>\n",
        "\n",
        "Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient Estimation of Word Representations in Vector Space. In Proceedings of Workshop at ICLR, 2013.\n",
        "\n",
        "Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. Distributed Representations of Words and Phrases and their Compositionality. In Proceedings of NIPS, 2013.\n",
        "\n",
        "Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. Linguistic Regularities in Continuous Space Word Representations. In Proceedings of NAACL HLT, 2013.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BjxtXRzOEqbK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fo1KH5wgEqbM",
        "outputId": "e2c0566c-b6cb-4d85-ad1e-eccdf1d889d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  capital_s country_s capital_t    country_t\n",
              "0    Athens    Greece   Bangkok     Thailand\n",
              "1    Athens    Greece   Beijing        China\n",
              "2    Athens    Greece    Berlin      Germany\n",
              "3    Athens    Greece      Bern  Switzerland\n",
              "4    Athens    Greece     Cairo        Egypt"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f18f0b5b-d771-469b-99fa-342c61dd0254\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>capital_s</th>\n",
              "      <th>country_s</th>\n",
              "      <th>capital_t</th>\n",
              "      <th>country_t</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Bangkok</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Beijing</td>\n",
              "      <td>China</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Bern</td>\n",
              "      <td>Switzerland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Cairo</td>\n",
              "      <td>Egypt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f18f0b5b-d771-469b-99fa-342c61dd0254')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f18f0b5b-d771-469b-99fa-342c61dd0254 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f18f0b5b-d771-469b-99fa-342c61dd0254');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e3d93184-860f-4a14-84a0-26a9d80bfaf1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3d93184-860f-4a14-84a0-26a9d80bfaf1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e3d93184-860f-4a14-84a0-26a9d80bfaf1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 4951,\n  \"fields\": [\n    {\n      \"column\": \"capital_s\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"Muscat\",\n          \"Berlin\",\n          \"Bratislava\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country_s\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"Oman\",\n          \"Germany\",\n          \"Slovakia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital_t\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"Nairobi\",\n          \"Cairo\",\n          \"Brussels\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country_t\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"Kenya\",\n          \"Egypt\",\n          \"Belgium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data = pd.read_csv('./data/capital_list.txt', delimiter=' ')\n",
        "data.columns = ['capital_s', 'country_s', 'capital_t', 'country_t']\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-ETiSYrEqbN"
      },
      "source": [
        "본 실습에서는, [google word2vec](https://code.google.com/archive/p/word2vec/) model을 이용한다.\n",
        "하지만, [The Original GoogleNews-vectors-negative300.bin.gz](https://code.google.com/archive/p/word2vec/).는 3.64GB로 용량이 매우 크기 때문에, 본 실습을 위하여 사용되는 몇 개의 단어에 대한 word vector만을 추출하여 사용한다.\n",
        "\n",
        "해당 추출 과정은 다음과 같은 과정으로 추출하여 제공하였다.\n",
        "\n",
        "<details>\n",
        "<summary>CODE 보기</summary>\n",
        "\n",
        "```python\n",
        "import nltk\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "embeddings = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary = True)\n",
        "\n",
        "f = open('capitals.txt', 'r').read()\n",
        "set_words = set(nltk.word_tokenize(f))\n",
        "assign_word = words = ['king', 'queen', 'oil', 'gas', 'happy', 'sad', 'city', 'town', 'village', 'country', 'continent', 'petroleum', 'joyful']\n",
        "\n",
        "for w in assign_word:\n",
        "    set_words.add(w)\n",
        "\n",
        "def get_word_embeddings(embeddings):\n",
        "\n",
        "    word_embeddings = {}\n",
        "    for word in embeddings.vocab:\n",
        "        if word in set_words:\n",
        "            word_embeddings[word] = embeddings[word]\n",
        "    return word_embeddings\n",
        "\n",
        "pickle.dump( get_word_embeddings(embeddings), open( \"word_embeddings_subset.p\", \"wb\" ) )\n",
        "```\n",
        "</details>\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wRrP41WrEqbO",
        "outputId": "411a04f7-8395-4edc-df27-9747ad927326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['country', 'city', 'China', 'Iraq', 'oil', 'town', 'Canada', 'London', 'England', 'Australia', 'Japan', 'Pakistan', 'Iran', 'gas', 'happy', 'Russia', 'Afghanistan', 'France', 'Germany', 'Georgia', 'Baghdad', 'village', 'Spain', 'Italy', 'Beijing', 'Jordan', 'Paris', 'Ireland', 'Turkey', 'Egypt', 'Lebanon', 'Taiwan', 'Tokyo', 'Nigeria', 'Vietnam', 'Moscow', 'Greece', 'Indonesia', 'sad', 'Syria', 'Thailand', 'Libya', 'Zimbabwe', 'Cuba', 'Ottawa', 'Tehran', 'Sudan', 'Kenya', 'Philippines', 'Sweden', 'Poland', 'Ukraine', 'Rome', 'Venezuela', 'Switzerland', 'Berlin', 'Bangladesh', 'Portugal', 'Ghana', 'Athens', 'king', 'Madrid', 'Somalia', 'Dublin', 'Qatar', 'Chile', 'Islamabad', 'Bahrain', 'Nepal', 'Norway', 'Serbia', 'Kabul', 'continent', 'Brussels', 'Belgium', 'Uganda', 'petroleum', 'Cairo', 'Denmark', 'Austria', 'Jamaica', 'Georgetown', 'Bangkok', 'Finland', 'Peru', 'Romania', 'Bulgaria', 'Hungary', 'Vienna', 'Kingston', 'Manila', 'Cyprus', 'Azerbaijan', 'Copenhagen', 'Fiji', 'Tunisia', 'Kazakhstan', 'queen', 'Beirut', 'Jakarta', 'Croatia', 'Belarus', 'Algeria', 'Malta', 'Morocco', 'Rwanda', 'Bahamas', 'Damascus', 'Ecuador', 'Angola', 'Canberra', 'Liberia', 'Honduras', 'Tripoli', 'Slovakia', 'Doha', 'Armenia', 'Taipei', 'Oman', 'Nairobi', 'Santiago', 'Guinea', 'Uruguay', 'Stockholm', 'Slovenia', 'Zambia', 'Havana', 'Uzbekistan', 'Belgrade', 'Mogadishu', 'Khartoum', 'Botswana', 'Kyrgyzstan', 'Dhaka', 'Namibia', 'Ankara', 'Abuja', 'Lima', 'Harare', 'Warsaw', 'Malawi', 'Lisbon', 'Latvia', 'Niger', 'Lithuania', 'Estonia', 'Samoa', 'Oslo', 'Nicaragua', 'Hanoi', 'Sofia', 'Macedonia', 'Senegal', 'Mozambique', 'Guyana', 'Mali', 'Accra', 'Kathmandu', 'Tbilisi', 'Helsinki', 'Montenegro', 'Caracas', 'Laos', 'Budapest', 'Kiev', 'Turkmenistan', 'Eritrea', 'Albania', 'Madagascar', 'Nassau', 'Kampala', 'Amman', 'Greenland', 'Belize', 'Moldova', 'Burundi', 'Tajikistan', 'Baku', 'Astana', 'Gambia', 'Bucharest', 'joyful', 'Monrovia', 'Mauritania', 'Algiers', 'Muscat', 'Bern', 'Luanda', 'Dakar', 'Tunis', 'Gabon', 'Minsk', 'Liechtenstein', 'Suva', 'Yerevan', 'Zagreb', 'Bishkek', 'Manama', 'Kigali', 'Riga', 'Lusaka', 'Tashkent', 'Nicosia', 'Valletta', 'Windhoek', 'Dominica', 'Quito', 'Tallinn', 'Bratislava', 'Tegucigalpa', 'Skopje', 'Gaborone', 'Rabat', 'Maputo', 'Suriname', 'Vilnius', 'Montevideo', 'Ljubljana', 'Tirana', 'Dushanbe', 'Ashgabat', 'Asmara', 'Tuvalu', 'Managua', 'Conakry', 'Banjul', 'Bamako', 'Lilongwe', 'Vientiane', 'Chisinau', 'Roseau', 'Nouakchott', 'Podgorica', 'Niamey', 'Bujumbura', 'Apia', 'Antananarivo', 'Libreville', 'Belmopan', 'Vaduz', 'Paramaribo', 'Nuuk', 'Funafuti'])\n",
            "243\n",
            "(300,)\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "word_embeddings = pickle.load(open('./data/word_embeddings_subset.p', 'rb'))\n",
        "print(word_embeddings.keys())\n",
        "print(len(word_embeddings))\n",
        "print(word_embeddings['country'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5bVgs31EqbP"
      },
      "source": [
        "## 1.2 Predict Capital of Country\n",
        "\n",
        "학습된 word2vec 모델을 이용해 단어 간 관계를 분석해보자.\n",
        "\n",
        "이를 위해, 강의노트에서 살펴본 예시에서와 같이 주어진 capital_list.txt file을 이용하여 단어간 관계를 계산하여 수도 이름을 예측하는 task를 해결하도록 한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "먼저, 두 벡터간 유사도를 구할 수 있는 함수를 구현하고, Word2Vec 모델을 이용해 word embedding을 구하여 두 단어간 유사도를 확인한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rk66Ckt0EqbQ",
        "outputId": "774a5790-d2fe-40de-c248-22c3e377e344",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.63349104\n",
            "0.37018886\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def cosine_similarity(u, v):\n",
        "    \"\"\"\n",
        "    Implement cosine similarity between two vectors here.\n",
        "    You can just use the code from the previous lab.\n",
        "    \"\"\"\n",
        "    dot = np.dot(u, v)\n",
        "    norm_u = np.sqrt(np.dot(u, u))\n",
        "    norm_v = np.sqrt(np.dot(v, v))\n",
        "\n",
        "    cosine_similarity = dot / (norm_u * norm_v)\n",
        "\n",
        "    return cosine_similarity\n",
        "\n",
        "print(cosine_similarity(word_embeddings['Paris'], word_embeddings['France']))\n",
        "print(cosine_similarity(word_embeddings['China'], word_embeddings['France']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4-aIk54EqbR"
      },
      "source": [
        "다음으로, task를 해결하기 위해 구현해야하는 함수는 다음과 같다.\n",
        "\n",
        "- Function은 3가지의 input word(string)를 받는다.\n",
        "    * 첫번째 input word는 source country 이다.\n",
        "    * 두번째 input word는 source capital 이다. 즉, 첫번째 input word의 수도이다.\n",
        "    * 세번째 input word는 target country 이다. 즉, 알고자하는 수도의 국가이다.\n",
        "\n",
        "</br>\n",
        "\n",
        "- Function은 1가지의 output word(string)를 반환한다.\n",
        "    * output word는 target country의 수도이다.\n",
        "\n",
        "</br>\n",
        "\n",
        "- Function은 word embedding을 활용하기 위해 사진 학습된 word2vec 모델을 input으로 받는다.\n",
        "\n",
        "</br>\n",
        "\n",
        "- Function은 다음과 같은 방식으로 작동한다.\n",
        "    * source capital embedding에서 source country embedding을 뺀다.\n",
        "    * 위에서 구한 벡터에 target country embedding을 더한다.\n",
        "    * 위에서 구한 벡터와 가장 유사한 단어를 찾는다.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "QcyDyoPrEqbS",
        "outputId": "4e804297-b895-4b78-b5ba-886295cf25d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rome\n"
          ]
        }
      ],
      "source": [
        "def predict_country(source_capital, source_country, target_country, word_embeddings):\n",
        "    \"\"\"\n",
        "    Implement the prediction function that described in the above cell.\n",
        "\n",
        "    source_capital =\n",
        "    source_country =\n",
        "    target_country =\n",
        "\n",
        "    predicted_capital_embedding =\n",
        "\n",
        "    max_similarity = -1\n",
        "    country = ''\n",
        "    for word, embedding in word_embeddings.items():\n",
        "        ~~\n",
        "\n",
        "    \"\"\"\n",
        "    source_capital_vector = word_embeddings[source_capital]\n",
        "    source_country_vector = word_embeddings[source_country]\n",
        "    target_country_vector = word_embeddings[target_country]\n",
        "\n",
        "    predicted_capital_embedding = source_capital_vector - source_country_vector + target_country_vector\n",
        "\n",
        "    max_similarity = -1\n",
        "    predicted_capital = ''\n",
        "\n",
        "    for word, embedding in word_embeddings.items():\n",
        "        if word not in [source_country, source_capital, target_country]:\n",
        "            similarity = cosine_similarity(predicted_capital_embedding, embedding)\n",
        "            if similarity > max_similarity:\n",
        "                max_similarity = similarity\n",
        "                predicted_capital = word\n",
        "\n",
        "    return predicted_capital\n",
        "\n",
        "print(predict_country('Paris', 'France', 'Italy', word_embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "JJxwJjf8EqbT",
        "outputId": "53a71da1-6009-458a-be4b-07034d21687e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8693193294283983\n"
          ]
        }
      ],
      "source": [
        "#Eval\n",
        "def compute_accuracy(word_embeddings, data):\n",
        "    num_correct = 0\n",
        "    for _, row in data.iterrows():\n",
        "        source_capital = row['capital_s']\n",
        "        source_country = row['country_s']\n",
        "        target_country = row['country_t']\n",
        "\n",
        "        predicted_capital = predict_country(source_capital, source_country, target_country, word_embeddings)\n",
        "\n",
        "        if predicted_capital == row['capital_t']:\n",
        "            num_correct += 1\n",
        "\n",
        "    accuracy = num_correct / len(data)\n",
        "    return accuracy\n",
        "\n",
        "print(compute_accuracy(word_embeddings, data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bqlf92ZEqbT"
      },
      "source": [
        "### 1.3 PCA\n",
        "\n",
        "Word2Vec을 통한 word간 embedding 수준에서의 distance를 plotting하여 살펴보자.\n",
        "\n",
        "현재 word2vec 모델은 [300]차원의 vector를 이용하여 단어를 표현하고 있다. 따라서, 이를 인간이 이해할 수 있는 [2]차원으로 축소하여 plotting을 진행한다.\n",
        "\n",
        "이를 위해, [PCA](https://en.wikipedia.org/wiki/Principal_component_analysis)를 이용하여 [300]차원의 vector를 [2]차원으로 축소한다.\n",
        "\n",
        "\n",
        "PCA를 계산하는 방법은, 다음과 같다.\n",
        "\n",
        "1. Data를 mean으로 normalize한다.\n",
        "2. Covariance matrix를 구한다.\n",
        "3. Covariance matrix의 eigenvalue와 eigenvector를 구한다.\n",
        "4. K개의 eigenvector를 선택한다.\n",
        "5. K개의 eigenvector를 이용해 K차원의 vector로 data를 projection한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jTO6BykWEqbU"
      },
      "outputs": [],
      "source": [
        "def compute_PCA(X, n_components=2):\n",
        "    X_demeaned = X - np.mean(X, axis=0)\n",
        "    cov_matrix = np.cov(X_demeaned, rowvar=False)\n",
        "    eigen_values, eigen_vectors = np.linalg.eigh(cov_matrix)\n",
        "    idx_sorted = np.argsort(eigen_values)[::-1]\n",
        "    eigen_values_sorted = eigen_values[idx_sorted]\n",
        "    eigen_vectors_sorted = eigen_vectors[:, idx_sorted]\n",
        "    eigen_vectors_subset = eigen_vectors_sorted[:, 0:n_components]\n",
        "    X_reduced = np.dot(eigen_vectors_subset.transpose(), X_demeaned.transpose()).transpose()\n",
        "    return X_reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cT_OkyhTEqbV",
        "outputId": "4401170a-3b67-4fb4-8f8c-309b0e92ade8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13, 300)\n"
          ]
        }
      ],
      "source": [
        "word_list = ['China', 'Italy', 'France', 'Berlin', 'Rome', 'Paris', 'Beijing', 'Germany', 'Japan', 'Tokyo', 'town', 'city', 'village']\n",
        "\n",
        "X = np.zeros((1, 300))\n",
        "for word in word_list:\n",
        "    X = np.row_stack((X, word_embeddings[word]))\n",
        "X = X[1:, :]\n",
        "\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2t86H7q0EqbW",
        "outputId": "bcce169c-c6f3-4eb8-b3cf-8eee65f274bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "X_reduced = compute_PCA(X, n_components=2)\n",
        "plt.scatter(X_reduced[:, 0], X_reduced[:, 1])\n",
        "for i, word in enumerate(word_list):\n",
        "    plt.annotate(word, xy=(X_reduced[i, 0], X_reduced[i, 1]))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttv3kcNQEqbW"
      },
      "source": [
        "## 2. CBOW vs Skip-gram\n",
        "\n",
        "- [Skip-gram]: Predict context words (surrounding words) given target word\n",
        "- [CBOW]: Predict target word from bag of context words\n",
        "\n",
        "예를 들어, 다음과 같은 문장이 있다고 하자.\n",
        "\n",
        "$$ \\text{\"I am happy because I am learning\"} $$\n",
        "\n",
        "Context size가 2라고 하면\n",
        "\n",
        "[CBOW]의 경우, target word \"happy\"를 예측하기 위해 \"I\", \"am\", \"because\", \"I\"를 이용한다.\n",
        "\n",
        "반면, [Skip-gram]의 경우, target word \"happy\"를 통해 \"I\", \"am\", \"because\", \"I\"를 예측한다.\n",
        "\n",
        "***\n",
        "\n",
        "### 2.1 CBOW\n",
        "\n",
        "CBOW 학습 과정에 대해 자세히 알아보자.\n",
        "\n",
        "위 예시에서의 경우, CBOW는 다음과 같이 학습된다.\n",
        "\n",
        "$$ \\text{Context = [\"I\", \"am\", \"because\", \"I\"]} $$\n",
        "$$ \\text{Target = [\"happy\"]} $$\n",
        "\n",
        "$$ \\text{Input = [\"I\", \"am\", \"because\", \"I\"]} $$\n",
        "$$ \\text{Output = [\"happy\"]} $$\n",
        "\n",
        "이때, 모델 구조는 다음과 같다.\n",
        "\n",
        "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='/content/drive/MyDrive/ai-intensive2/lab3/data/word2.png?raw=1' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:600px;height:250px;\" />  </div>\n",
        "\n",
        "이때, $\\bar x$는 input context word들의 one-hot vector의 평균을 의미한다.\n",
        "\n",
        "$$ \\bar x = \\frac{1}{4} \\sum_{i=1}^{4} x_i $$\n",
        "\n",
        "최종적으로 정리하자면,\n",
        "\n",
        "$$ h = W_{1}X + b_1 $$\n",
        "$$ a = ReLU(h) $$\n",
        "$$ z = W_{2}a + b_2 $$\n",
        "$$ \\hat y = softmax(z) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1MOjBXePEqbX",
        "outputId": "b4a0e3b8-aad6-4d45-8cd1-c15f64291746",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "lemm = nltk.stem.WordNetLemmatizer()\n",
        "stemmer = nltk.stem.PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "De9NDVbuEqbY"
      },
      "outputs": [],
      "source": [
        "with open('./data/shakespeare.txt') as f:\n",
        "    corpus = f.read()\n",
        "\n",
        "\"\"\"\n",
        "In here, you should implement preprocessing step\n",
        "1. Replace all non-alphabetic characters with space (you can use regex or isalpha() function either)\n",
        "2. Replece all punctuations(, ! ? ; -) with period (you should use regex)\n",
        "3. Tokenize the corpus (you can use nltk.word_tokenize() function)\n",
        "\n",
        "like..\n",
        "\n",
        "corpus = re.sub(~~~~)\n",
        "\n",
        "This preprocessing step is very important to get good performance influencing on after all steps.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "corpus = nltk.word_tokenize(corpus)\n",
        "corpus = [token.lower() for token in corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nofh8P9fEqbZ",
        "outputId": "3ee24030-681b-4a36-98f3-3792b8cae7da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6432\n",
            "[(',', 4689), ('.', 3518), ('the', 1520), ('and', 1394), ('i', 1269), ('to', 1159), ('of', 1092), ('my', 857), (';', 782), ('that', 781)]\n"
          ]
        }
      ],
      "source": [
        "freq_dist = nltk.FreqDist(word for word in corpus) #Means frequency distribution\n",
        "print(len(freq_dist))\n",
        "print(freq_dist.most_common(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "h2UEQbAPEqba",
        "outputId": "4fc9aff7-40d7-4aa7-bf30-e7dc7e76e9d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "471\n",
            "!\n",
            "6432\n"
          ]
        }
      ],
      "source": [
        "words = sorted(list(set(corpus)))\n",
        "idx = 0\n",
        "word2idx, idx2word = {}, {}\n",
        "for x in words:\n",
        "    word2idx[x] = idx\n",
        "    idx2word[idx] = x\n",
        "    idx += 1\n",
        "\n",
        "print(word2idx['apple'])\n",
        "print(idx2word[0])\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASO5YOWJEqba"
      },
      "source": [
        "### 2.2 Training model\n",
        "\n",
        "CBOW 모델을 학습시키기 위해, 다음과 같은 과정을 따라간다.\n",
        "\n",
        "- 1. Model Layer Initialization\n",
        "- 2. Forward Propagation\n",
        "- 3. Loss Function\n",
        "- 4. Backward Propagation\n",
        "- 5. Gradient Descent\n",
        "\n",
        "먼저, Model Layer Initialization을 진행한다.\n",
        "\n",
        "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='https://github.com/dh610/ai-intensive2/blob/main/lab3/data/word2.png?raw=1' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:600px;height:250px;\" />  </div>\n",
        "\n",
        "- 첫번째 matrix $W_1$은 $N \\times V$의 크기를 가진다.\n",
        "    * $N$은 word vector의 차원이다.\n",
        "    * $V$는 vocabulary size이다.\n",
        "\n",
        "\n",
        "- 두번째 matrix $W_2$는 $V \\times N$의 크기를 가진다.\n",
        "    * $V$는 vocabulary size이다.\n",
        "    * $N$은 word vector의 차원이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "- 첫번째 bias $b_1$은 [BLANK]의 크기를 가진다.\n",
        "    \n",
        "- 두번째 bias $b_2$는 [BLANK]의 크기를 가진다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fDLjb7f4Eqba"
      },
      "outputs": [],
      "source": [
        "def init_model(N, V):\n",
        "    np.random.seed(42)\n",
        "\n",
        "    W1 = np.random.rand(N, V)\n",
        "    W2 = np.random.rand(V, N)\n",
        "\n",
        "    b1 = np.zeros((N, 1))\n",
        "    b2 = np.zeros((V, 1))\n",
        "\n",
        "    return W1, W2, b1, b2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvDVVZV3Eqbb"
      },
      "source": [
        "Softmax\n",
        "\n",
        "$$ \\text{softmax}(z_i) = \\frac{e^{z_i} }{\\sum_{i=0}^{V-1} e^{z_i} }  \\tag{5} $$\n",
        "\n",
        "- V는 vocabulary size이다.\n",
        "- $z_i$는 $i$번째 단어의 score이다.\n",
        "- i는 0부터 V-1까지의 단어를 의미한다. (idx가 0부터 시작)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RMEmdhRjEqbb"
      },
      "outputs": [],
      "source": [
        "def softmax(z):\n",
        "    e_z = np.exp(z)\n",
        "    return e_z / np.sum(e_z, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq3v2rGEEqbc"
      },
      "source": [
        "### Forward\n",
        "\n",
        "Forward propagation은 다음과 같이 진행할 수 있다.\n",
        "\n",
        "$$ h = W_{1}X + b_1 $$\n",
        "$$ a = ReLU(h) $$\n",
        "$$ z = W_{2}a + b_2 $$\n",
        "\n",
        "이때, ReLU function은 다음과 같이 정의된다.\n",
        "\n",
        "$$ ReLU(x) = \\max(0,x) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "EaS3xYeuEqbd"
      },
      "outputs": [],
      "source": [
        "def ReLU(x):\n",
        "    \"\"\"\n",
        "    Implement own ReLU function here\n",
        "    You can use np library\n",
        "    \"\"\"\n",
        "    return np.maximum(0, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "76M7tOWMEqbd"
      },
      "outputs": [],
      "source": [
        "def forward(x, W1, W2, b1, b2):\n",
        "    \"\"\"\n",
        "    You should implement forward function that described in the above cell.\n",
        "    h =\n",
        "    a =\n",
        "    z =\n",
        "    \"\"\"\n",
        "\n",
        "    h = np.dot(W1, x) + b1\n",
        "    a = ReLU(h)\n",
        "    z = np.dot(W2, a) + b2\n",
        "\n",
        "    return z, a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRvmQvqdEqbe"
      },
      "source": [
        "### Loss\n",
        "\n",
        "Cost function은 다음과 같이 cross entropy loss function을 이용한다.\n",
        "\n",
        "$$ cross\\_entropy(y, \\hat y) = - \\sum_{i=0}^{V-1} [ y_i \\log(\\hat y_i) + (1-y_i) \\log(1-\\hat y_i) ]$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "JlBHQCqWEqbe"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_loss(y, y_hat, batch_size):\n",
        "    \"\"\"\n",
        "    You should implement cross entropy loss function that described in the above cell. (just one line)\n",
        "    log_probs =\n",
        "\n",
        "    I provide you summation part here, with the shape of batch size\n",
        "    cost = -1/batch_size * np.sum(log_probs)\n",
        "    cost = np.squeeze(cost) #squeeze is used for removing single-dimensional entries from the shape of an array.\n",
        "    \"\"\"\n",
        "\n",
        "    log_probs = np.multiply(y, np.log(y_hat)) + np.multiply(1 - y, np.log(1 - y_hat))\n",
        "\n",
        "    cost = -1/batch_size * np.sum(log_probs)\n",
        "    cost = np.squeeze(cost)\n",
        "\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-PmL4ZkEqbf"
      },
      "source": [
        "### Backpropagation\n",
        "\n",
        "지금까지 CBOW model이 어떻게 동작하는지 학습했다.\n",
        "모델을 구조를 Initalize하고, Forward 함수를 정의하였으며, Cost functinon 또한 정의하였다.\n",
        "\n",
        "이제, Gradient를 계산하여 Back-propagation을 진행하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1k8hMk_JEqbf"
      },
      "outputs": [],
      "source": [
        "def back_propagation(x, y_hat, y, h, W1, W2, b1, b2, batch_size):\n",
        "    l1 = np.dot(W2.T, (y_hat - y)) #l1 means layer1\n",
        "    l1 = ReLU(l1)\n",
        "\n",
        "    grad_W1 = (1/batch_size) * np.dot(l1, x.T)\n",
        "    grad_W2 = (1/batch_size) * np.dot(y_hat - y, h.T)\n",
        "\n",
        "    grad_b1 = np.sum((1/batch_size) * np.dot(l1, x.T), axis=1, keepdims=True)\n",
        "    grad_b2 = np.sum((1/batch_size) * np.dot(y_hat-y, h.T), axis=1, keepdims=True)\n",
        "\n",
        "    return grad_W1, grad_W2, grad_b1, grad_b2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "02kyoP8sEqbg"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "!NOTE\n",
        "This cell provide you just useful functions for training to deal with batch.\n",
        "You don't need to implement anything in here.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "def pack_idx_with_frequency(context_words, word2idx):\n",
        "    freq_dict = defaultdict(int)\n",
        "    for word in context_words:\n",
        "        freq_dict[word] += 1\n",
        "    idxs = get_idx(context_words, word2idx)\n",
        "    packed = []\n",
        "    for i in range(len(idxs)):\n",
        "        idx = idxs[i]\n",
        "        freq = freq_dict[context_words[i]]\n",
        "        packed.append((idx, freq))\n",
        "    return packed\n",
        "\n",
        "def get_idx(words, word2idx):\n",
        "    idx = []\n",
        "    for word in words:\n",
        "        idx = idx + [word2idx[word]]\n",
        "    return idx\n",
        "\n",
        "def get_vectors(data, word2idx, V, C):\n",
        "    i = C\n",
        "    while True:\n",
        "        y = np.zeros(V)\n",
        "        x = np.zeros(V)\n",
        "        center_word = data[i]\n",
        "        y[word2idx[center_word]] = 1\n",
        "        context_words = data[(i - C):i] + data[(i+1):(i+C+1)]\n",
        "        num_ctx_words = len(context_words)\n",
        "        for idx, freq in pack_idx_with_frequency(context_words, word2idx):\n",
        "            x[idx] = freq/num_ctx_words\n",
        "        yield x, y\n",
        "        i += 1\n",
        "        if i >= len(data):\n",
        "            print('i is being set to 0')\n",
        "            i = 0\n",
        "\n",
        "def get_batches(data, word2idx, V, C, batch_size):\n",
        "    batch_x = []\n",
        "    batch_y = []\n",
        "    for x, y in get_vectors(data, word2idx, V, C):\n",
        "        while len(batch_x) < batch_size:\n",
        "            batch_x.append(x)\n",
        "            batch_y.append(y)\n",
        "        else:\n",
        "            yield np.array(batch_x).T, np.array(batch_y).T\n",
        "\n",
        "def get_dict(data):\n",
        "    words = sorted(list(set(data)))\n",
        "    n = len(words)\n",
        "    idx = 0\n",
        "\n",
        "    word2idx = {}\n",
        "    idx2word = {}\n",
        "    for k in words:\n",
        "        word2idx[k] = idx\n",
        "        idx2word[idx] = k\n",
        "        idx += 1\n",
        "    return word2idx, idx2word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdy63RuOEqbh"
      },
      "source": [
        "### Gradient Descent\n",
        "\n",
        "Backpropagation을 통해 gradient를 계산할 수 있게 되었다.\n",
        "\n",
        "이제, gradient descent를 통해 parameter를 update할 수 있도록 한다.\n",
        "\n",
        "그리고 해당 과정을 통해 모델의 학습을 진행하고, loss를 확인한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nLU7GGDDEqbh"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(data, word2idx, V, N, num_iters, batch_size, window_size):\n",
        "    iters = 0\n",
        "    \"\"\"\n",
        "    You should implement gradient descent algorithm here.\n",
        "    You use all of the functions that you have implemented above.\n",
        "\n",
        "    init model\n",
        "\n",
        "    for x, y in get_batches(data, word2idx, V, window_size, batch_size):\n",
        "        z, h =\n",
        "        y_hat =\n",
        "\n",
        "        cost =\n",
        "        if ((iters+1) % 10 == 0): #This line is for printing cost every 10 iterations < DO NOT CHANGE THIS LINE >\n",
        "            print(f\"iters: {iters + 1} cost: {cost:.6f}\")\n",
        "\n",
        "        do back-propagation\n",
        "\n",
        "        iters += 1\n",
        "        if iters == num_iters:\n",
        "            break\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    W1, W2, b1, b2 = init_model(N, V)\n",
        "\n",
        "    for x, y in get_batches(data, word2idx, V, window_size, batch_size):\n",
        "        z, h = forward(x, W1, W2, b1, b2)\n",
        "        y_hat = softmax(z)\n",
        "\n",
        "        cost = cross_entropy_loss(y, y_hat, batch_size)\n",
        "\n",
        "        if ((iters+1) % 10 == 0): #This line is for printing cost every 10 iterations < DO NOT CHANGE THIS LINE >\n",
        "            print(f\"iters: {iters + 1} cost: {cost:.6f}\")\n",
        "\n",
        "        grad_W1, grad_W2, grad_b1, grad_b2 = back_propagation(x, y_hat, y, h, W1, W2, b1, b2, batch_size)\n",
        "\n",
        "        W1 -= 0.001 * grad_W1\n",
        "        W2 -= 0.001 * grad_W2\n",
        "        b1 -= 0.01 * grad_b1\n",
        "        b2 -= 0.01 * grad_b2\n",
        "\n",
        "        iters += 1\n",
        "        if iters == num_iters:\n",
        "            break\n",
        "\n",
        "    return W1, W2, b1, b2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8hVWsHSEEqbi",
        "outputId": "a4e4d88d-fdc0-4206-e92e-a0033993043b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters: 10 cost: 8.461147\n",
            "iters: 20 cost: 5.657198\n",
            "iters: 30 cost: 3.055674\n",
            "iters: 40 cost: 1.280919\n",
            "iters: 50 cost: 0.619907\n",
            "iters: 60 cost: 0.380475\n",
            "iters: 70 cost: 0.268756\n",
            "iters: 80 cost: 0.206092\n",
            "iters: 90 cost: 0.166505\n",
            "iters: 100 cost: 0.139402\n",
            "iters: 110 cost: 0.119753\n",
            "iters: 120 cost: 0.104885\n",
            "iters: 130 cost: 0.093259\n",
            "iters: 140 cost: 0.083928\n",
            "iters: 150 cost: 0.076279\n",
            "iters: 160 cost: 0.069897\n",
            "iters: 170 cost: 0.064494\n",
            "iters: 180 cost: 0.059861\n",
            "iters: 190 cost: 0.055846\n",
            "iters: 200 cost: 0.052334\n",
            "iters: 210 cost: 0.049236\n",
            "iters: 220 cost: 0.046483\n",
            "iters: 230 cost: 0.044021\n",
            "iters: 240 cost: 0.041806\n",
            "iters: 250 cost: 0.039803\n",
            "iters: 260 cost: 0.037982\n",
            "iters: 270 cost: 0.036321\n",
            "iters: 280 cost: 0.034799\n",
            "iters: 290 cost: 0.033400\n",
            "iters: 300 cost: 0.032108\n"
          ]
        }
      ],
      "source": [
        "word2idx, idx2word = get_dict(corpus)\n",
        "\n",
        "W1, W2, b1, b2 = gradient_descent(corpus, word2idx, len(word2idx), N=50, num_iters=300,  batch_size=128, window_size=2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cpwan",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}