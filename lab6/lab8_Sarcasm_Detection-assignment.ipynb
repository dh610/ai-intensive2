{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8 : Sarcasm Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@copyright: \n",
    "    (c) 2023. iKnow Lab. Ajou Univ., All rights reserved.\n",
    "\n",
    "M.S. Student: Wansik-Jo (jws5327@ajou.ac.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For assignment\n",
    "\n",
    "- Python code의 주석 처리되어있는 부분을 구현하면 됩니다.\n",
    "- MD 형식의 Cell의 [BLANK] 부분을 채우면 됩니다.\n",
    "- MD 형식의 Cell의 [ANSWER] 부분 이후에 답을 작성하면 됩니다.\n",
    "- 조교에게 퀴즈의 답과 함께 코드 실행 결과를 보여준 뒤, BB에 제출 후 가시면 됩니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 목차\n",
    "\n",
    "1. Sarcasm Detection\n",
    "2. Data Preprocessing\n",
    "3. Modeling\n",
    "4. Training / Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sarcasm Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sarcasm Detection` task는 target 문장이 sarcastic한지 아닌지를 판별하는 task이다.\n",
    "\n",
    "[ACL2020 dataset](https://github.com/EducationalTestingService/sarcasm)을 사용한다. 해당 dataset은 3개의 column으로 구성되어 있다.\n",
    "\n",
    "- `label`: sarcastic 여부를 나타내는 binary value (NOT-SARCASM: non-sarcastic, SARCASM: sarcastic)\n",
    "- `response`: target 문장\n",
    "- `context`: target 문장 앞 문장들 (최대 20)\n",
    "\n",
    "### 본 실습에서는, 지금까지 배운 내용을 활용하여 Dataset의 이해 및 전처리, 배운 Model의 Implement 및 비교, 그리고 학습 및 평가를 진행한다. \n",
    "\n",
    "- 원하는 전처리, 모델, 학습 방법을 적절히 선택하여 진행하고, 여러 실험을 통해 최적의 결과를 얻도록 한다.\n",
    "- 그 과정에서 변경하는 모델의 구조 및 전처리 방법, 학습 전략, 하이퍼파라미터 등을 기록하고, 그에 따른 결과 및 해석을 함께 기록한다. (해당 기록을 평가) \n",
    "- 최종적으로, 75% 이상의 accuracy를 달성하도록 한다.\n",
    "- 본 실습에서는 가장 간단한 BertForSequenceClassification 모델을 사용한다. 해당 코드를 참고하여 진행하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/EducationalTestingService/sarcasm.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "with open(\"./sarcasm/twitter/sarcasm_detection_shared_task_twitter_training.jsonl\", 'r', encoding=\"utf-8\") as file:\n",
    "    datalines = file.readlines()\n",
    "\n",
    "data = []\n",
    "for line in datalines:\n",
    "    data.append(json.loads(line))\n",
    "\n",
    "print(\"Data 개수: \", len(data))\n",
    "print(\"Data 예시: \")\n",
    "pprint.pprint(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 전처리. Data를 직접 살펴보며 Emoji, URL, Special Character 등 적절한 처리를 진행하도록 한다.\n",
    "import json\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'@user', '', sentence)\n",
    "\n",
    "    return sentence.strip()\n",
    "\n",
    "# Example\n",
    "print(\"Before: \", data[0]['response'])\n",
    "print(\"After: \", preprocess_sentence(data[0]['response']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class SarcasmDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        #원하는 Hyperparameter를 추가하여도 된다.\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        context = preprocess_sentence(\n",
    "        response = preprocess_sentence(\n",
    "        label = \n",
    "\n",
    "        #적절한 Context와 Response를 결합하여 Input으로 사용하도록 한다. Context 길이 또한 고려하여야하는 Hyperparameter이다.\n",
    "        input = \n",
    "\n",
    "        # Tokenizing\n",
    "        input_ids = self.tokenizer.encode(input)\n",
    "        token_type_ids = \n",
    "        attention_mask = \n",
    "\n",
    "        return input_ids, token_type_ids, attention_mask, label\n",
    "    \n",
    "# Example\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset = SarcasmDataset(data, tokenizer, 256)\n",
    "\n",
    "print(\"original_sentence\", data[0]['context'][-1], data[0]['response'])\n",
    "print(\"Input_ids: \", dataset[0][0])\n",
    "print(\"Token_type_ids: \", dataset[0][1])\n",
    "print(\"Attention_mask: \", dataset[0][2])\n",
    "print(\"Label: \", dataset[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate function considering padding\n",
    "def collate_fn(batch):\n",
    "    max_len = max(max(len(item[0]), len(item[1]), len(item[2])) for item in batch)  # Find max length in batch\n",
    "\n",
    "    input_ids, token_type_ids, attention_mask, labels = [], [], [], []\n",
    "    for item in batch:\n",
    "        # Padding each sequence to the max length\n",
    "        input_ids.append(item[0] + [0] * (max_len - len(item[0])))\n",
    "        token_type_ids.append(item[1] + [0] * (max_len - len(item[1])))\n",
    "        attention_mask.append(item[2] + [0] * (max_len - len(item[2])))\n",
    "        labels.append(item[3])\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.LongTensor(input_ids)\n",
    "    token_type_ids = torch.LongTensor(token_type_ids)\n",
    "    attention_mask = torch.LongTensor(attention_mask)\n",
    "    labels = torch.LongTensor(labels)\n",
    "\n",
    "    return input_ids, token_type_ids, attention_mask, labels\n",
    "\n",
    "# Example\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "for x in dataloader:\n",
    "    print(\"Input_ids: \", x[0])\n",
    "    print(\"Token_type_ids: \", x[1])\n",
    "    print(\"Attention_mask: \", x[2])\n",
    "    print(\"Label: \", x[3])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_data = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Test data\n",
    "with open(\"./sarcasm/twitter/sarcasm_detection_shared_task_twitter_testing.jsonl\", 'r', encoding=\"utf-8\") as file:\n",
    "    datalines = file.readlines()\n",
    "\n",
    "test_data = []\n",
    "for line in datalines:\n",
    "    test_data.append(json.loads(line))\n",
    "\n",
    "test_dataset = SarcasmDataset(test_data, tokenizer, 256)\n",
    "test_data = DataLoader(test_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "import torch.nn as nn\n",
    "\n",
    "class SarcasmDetectionModel(nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(SarcasmDetectionModel, self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(model_name, num_labels=num_labels)\n",
    "        self.encoder = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        outputs = self.encoder(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "        pooled_output = #WHAT IS THIS?\n",
    "        \n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# Example\n",
    "model = SarcasmDetectionModel(\"bert-base-uncased\", num_labels=2).cuda()\n",
    "\n",
    "for x in train_data:\n",
    "    input_ids, token_type_ids, attention_mask, labels = x\n",
    "    logits = model(input_ids.cuda(), token_type_ids=token_type_ids.cuda(), attention_mask=attention_mask.cuda())\n",
    "    print(\"Input_ids: \", input_ids)\n",
    "    print(\"Token_type_ids: \", token_type_ids)\n",
    "    print(\"Attention_mask: \", attention_mask)\n",
    "    print(\"Logits: \", logits)\n",
    "    print(\"Result: \", torch.argmax(logits, dim=-1))\n",
    "    print(\"Label: \", labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer, In here you can use any optimizer you want.\n",
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-6)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Example\n",
    "input_ids, token_type_ids, attention_mask, labels = next(iter(train_data))\n",
    "output = model(input_ids.cuda(), token_type_ids.cuda(), attention_mask.cuda())\n",
    "print(\"Output: \", output)\n",
    "print(\"Gold: \", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for input_ids, token_type_ids, attention_mask, labels in tqdm(train_data):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input_ids.cuda(), token_type_ids.cuda(), attention_mask.cuda())\n",
    "        loss = loss_fn(output, labels.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    for input_ids, token_type_ids, attention_mask, labels in tqdm(test_data):\n",
    "        output = model(input_ids.cuda(), token_type_ids.cuda(), attention_mask.cuda())\n",
    "        prediction = torch.argmax(output, dim=-1)\n",
    "        tp += \n",
    "        fp += \n",
    "        fn += \n",
    "        tn += \n",
    "        total += len(labels)\n",
    "\n",
    "    print(\"Accuracy: \", (tp + tn) / total)\n",
    "    print(\"Precision: \", tp / (tp + fp))\n",
    "    print(\"Recall: \", tp / (tp + fn))\n",
    "    print(\"F1: \", 2 * tp / (2 * tp + fp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpwan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
