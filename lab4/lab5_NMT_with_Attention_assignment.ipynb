{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dh610/ai-intensive2/blob/main/lab4/lab5_NMT_with_Attention_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/ai-intensive2\n",
        "!git pull\n",
        "%cd lab4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIfvKI61dpKd",
        "outputId": "fbabd348-77c9-44ff-e29b-b9e03337e35e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/ai-intensive2\n",
            "Already up to date.\n",
            "/content/drive/MyDrive/ai-intensive2/lab4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ_DnIzpdhyP"
      },
      "source": [
        "# Lab 5 : Neural Machine Translation with Attention Mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMnNoID5dhyR"
      },
      "source": [
        "@copyright:\n",
        "    (c) 2023. iKnow Lab. Ajou Univ., All rights reserved.\n",
        "\n",
        "M.S. Student: Wansik-Jo (jws5327@ajou.ac.kr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk9QkrREdhyS"
      },
      "source": [
        "# For assignment\n",
        "\n",
        "- Python code의 주석 처리되어있는 부분을 구현하면 됩니다.\n",
        "- MD 형식의 Cell의 [BLANK] 부분을 채우면 됩니다.\n",
        "- MD 형식의 Cell의 [ANSWER] 부분 이후에 답을 작성하면 됩니다.\n",
        "- 조교에게 퀴즈의 답과 함께 코드 실행 결과를 보여준 뒤, BB에 제출 후 가시면 됩니다.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVgvwD0zdhyT"
      },
      "source": [
        "\n",
        "## 목차\n",
        "\n",
        "1. Neural Machine Translation\n",
        "    - Task\n",
        "    - Data\n",
        "    - Model\n",
        "2. Attention Mechanism\n",
        "    - Attention\n",
        "    - Implementation\n",
        "    - Training\n",
        "    - Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sNuI9ACdhyU"
      },
      "source": [
        "## 1. Neural Machine Translation (Data & Model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzzrvzTjdhyU"
      },
      "source": [
        "### Task\n",
        "\n",
        "- 이번 챕터에서는 Neural Machine Translation (NMT)에 대해 다루며, Seq2Seq 모델에 대해 알아본다.\n",
        "- 특히, 지난시간 학습한 Seq2Seq 모델에 Attention Mechanism을 추가하여 NMT를 구현해본다.\n",
        "\n",
        "- 본 실습에서는, French to English 번역을 수행하는 NMT 모델을 구현한다.\n",
        "\n",
        "[KEY: > input, = target, < output]\n",
        "\n",
        "\\ > il est en train de peindre un tableau .\n",
        "\n",
        "\\ = he is painting a picture .\n",
        "\n",
        "\\ < he is painting a picture ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abrDbdIkdhyV"
      },
      "source": [
        "- 지난 시간에 학습한 Seq2Seq 모델은 Encoder와 Decoder로 구성되어 있으며, Encoder는 입력 문장을 의미 벡터로 변환하고, Decoder는 의미 벡터를 입력으로 받아 번역 문장을 생성한다.\n",
        "- 이 모델을 발전시키기 위해, Attention Mechanism을 추가한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXnY3deZdhyW"
      },
      "source": [
        "### Data\n",
        "\n",
        "https://www.manythings.org/anki/\n",
        "\n",
        "- 본 실습에서는, 위의 링크에서 다운로드 받은 Korean to English 번역 데이터를 사용한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X-YBOVUjdhyW"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o_MwUjUdhyY"
      },
      "source": [
        "- 언어의 각 단어를 one-hot vector로 표현한다.\n",
        "\n",
        "- 나중에 network의 입력과 출력으로 사용하기 위해, 각 단어를 index로 표현한다.\n",
        "- word2idx, idx2word dictionary를 가지는 helper class `Lang`을 정의한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3L-4qrDGdhyY"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XMpy1CmCdhyY"
      },
      "outputs": [],
      "source": [
        "# File consist of Unicode, so make it to String\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    return s.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXdsN0V5dhyZ"
      },
      "source": [
        "- Datafile을 읽고, line별로 나눈다. 또한 line을 pari 별로 나눈다.\n",
        "- Data는 English->French로 되어있으므로, reverse flag를 통해 French->English로 바꿀 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Tla3G_KzdhyZ"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse):\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "W2nqcZr4dhyZ"
      },
      "outputs": [],
      "source": [
        "#Filter out too short sentence\n",
        "#Also process apostrophes\n",
        "\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IzEvQsHadhya",
        "outputId": "bbd88aff-83cf-41a8-a87a-8c8cecfb4980",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counted words:\n",
            "kor 149\n",
            "eng 131\n",
            "['그는 흰 옷을 입고 있다 .', 'she is dressed in white .']\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    pairs = filterPairs(pairs)\n",
        "\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'kor', True)\n",
        "print(pairs[42])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATCFdlW4dhyb"
      },
      "source": [
        "- torch module을 활용하여, Prepare한 data를 Tensor로 변환하고, DataLoader를 정의한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZYB9AuSwdhyb"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'kor', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GguRGKhPdhyb"
      },
      "source": [
        "### Model\n",
        "\n",
        "- 지난 시간에 학습한 Seq2Seq 모델은 Encoder와 Decoder로 구성되어 있으며, Encoder는 입력 문장을 의미 벡터로 변환하고, Decoder는 의미 벡터를 입력으로 받아 번역 문장을 생성한다.\n",
        "\n",
        "- 본 실습에서는, torch nn module을 사용하여 Encoder와 Decoder를 구현한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl6ftFfZdhyb"
      },
      "source": [
        "### Encoder\n",
        "![Encoder RNN](https://github.com/dh610/ai-intensive2/blob/main/lab4/data/encoder_network.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xXuY1_8ldhyc"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        # Fill this cell to implement encoder RNN\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Fill this cell to implement forward pass of encoder RNN\n",
        "        output = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(output)\n",
        "\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcqSUhsFdhyc"
      },
      "source": [
        "### Decoder\n",
        "![Decoder RNN](https://github.com/dh610/ai-intensive2/blob/main/lab4/data/decoder_network.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VGb6lokHdhyc"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        # Fill this cell to implement decoder RNN\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden) #Fill here\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, None\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        #Fill this cell to implement forward step of decoder RNN\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrdghwlzdhyd"
      },
      "source": [
        "## 2. Attention Mechanism\n",
        "\n",
        "### Attention\n",
        "\n",
        "- En-Decoder 사이 latent vector만 전달되는 경우, 해당 vector에 모든 정보가 담겨있어야 한다.\n",
        "\n",
        "- Attention Mechanism은 Decoder가 출력을 생성할 때, Encoder의 모든 입력을 고려하는 것이 아니라, 해당 출력에 대해 필요한 입력만을 \"집중\"(Attention)하도록 한다.\n",
        "\n",
        "![Attention Mechanism](https://github.com/dh610/ai-intensive2/blob/main/lab4/data/attention_mechanism.png?raw=1)\n",
        "\n",
        "- 먼저, Attention weight를 계산한다.\n",
        "\n",
        "- 여기에 Encoder의 출력을 곱하여, Attention value를 계산한다.\n",
        "\n",
        "- Attention value는 입력 sequence의 특정 부분에 집중하여, 해당 부분의 정보를 Decoder에 전달한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdFZ4Jjydhye"
      },
      "source": [
        "### Additive Attention\n",
        "\n",
        "- [Additive Attention](https://arxiv.org/pdf/1409.0473.pdf)(Bahdanau Attention)은 다음과 같은 식으로 계산된다.\n",
        "\n",
        "$$ score(s_{t}, h_{s}) = v_{a}^{T} tanh(W_{a}s_{t} + U_{a}h_{s}) $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Jl8vFlHPdhye"
      },
      "outputs": [],
      "source": [
        "class AdittiveAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AdittiveAttention, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        #\"\"\" Fill this cell to implement additive attention, the Wa, Ua, Va\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, key):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(key))) #fill this cell, calculate scores\n",
        "        scores = scores.squeeze(2).unsqueeze(1) # (batch_size, 1, seq_len)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, key)\n",
        "\n",
        "        return context, weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMK_vJAXdhyf"
      },
      "source": [
        "### Implementation\n",
        "\n",
        "해당 Attention module을 적용하여, Decoder를 다시 작성한다.\n",
        "\n",
        "![Decoder RNN with Attention](https://github.com/dh610/ai-intensive2/blob/main/lab4/data/attention-decoder-network.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "brQh7gHVdhyf"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = AdittiveAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        \"\"\" Fill this cell to implement forward step of decoder RNN with attention\n",
        "            See above cells for reference\"\"\"\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat([embedded, context], dim = 2)\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCjGeSX_dhyf"
      },
      "source": [
        "### Training\n",
        "\n",
        "- 구현한 Encoder, Decoder 모델을 학습시킨다.\n",
        "- Dataloader를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4j3ClBEjdhyf"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        #Zero the gradients\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        #Encoder\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        #Decoder\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        #Loss\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters with optimizers\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zTCI6yX1dhyf"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100):\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('Epoch %d %.4f' % (epoch, print_loss_avg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AVTOz59ldhyg"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2q8Gs10udhyg"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vVmRU6zndhyg",
        "outputId": "fc793c34-8452-4da5-bbfc-4a6860358471",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counted words:\n",
            "kor 149\n",
            "eng 131\n",
            "> 그녀는 아름답다 .\n",
            "= she is beautiful .\n",
            "< playing dark-skinned am playing real really real real same too\n",
            "\n",
            "> 그분은 절대 그런 걸 할 사람이 아니에요 .\n",
            "= he is above doing such a thing .\n",
            "< playing very next really he real real same am married\n",
            "\n",
            "> 그는 서핑에 정말 미쳐있다 .\n",
            "= he is really crazy about surfing .\n",
            "< playing he afternoon i real same month person go real\n",
            "\n",
            "> 그는 학급에서 가장 둔한 아이이다 .\n",
            "= he is the dumbest kid in the class .\n",
            "< very i real bank real real same month same we\n",
            "\n",
            "> 그는 출생지로 따지면 독일인입니다 .\n",
            "= he is german by birth .\n",
            "< playing very next next employed too too a a easygoing\n",
            "\n",
            "> 그 사람은 미혼이에요 .\n",
            "= he is unmarried .\n",
            "< job job tomorrow am friends longer responsibility dumbest dumbest married\n",
            "\n",
            "> 그는 출생지로 따지면 독일인입니다 .\n",
            "= he is german by birth .\n",
            "< playing very next really same friends alone real same am\n",
            "\n",
            "> 나는 인간이야 .\n",
            "= i am human .\n",
            "< playing i easygoing dressed beauty at the <EOS>\n",
            "\n",
            "> 그는 영어를 모국어로 사용한다 .\n",
            "= he is a native english speaker .\n",
            "< health artist beauty real real same am not playing real\n",
            "\n",
            "> 그는 구직 중이다 .\n",
            "= he is looking for a job .\n",
            "< honest we too a easygoing nice nice next really friends\n",
            "\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "evaluateRandomly(encoder, decoder)\n",
        "# train(train_dataloader, encoder, decoder, 50, print_every=5)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cpwan",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}