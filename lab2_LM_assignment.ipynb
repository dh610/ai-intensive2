{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/MyDrive/ai-intensive2"
      ],
      "metadata": {
        "id": "w_W1CsMjCSJ_",
        "outputId": "25a71578-6a7c-49b9-9f8d-36150dfbe602",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/MyDrive/ai-intensive2'\n",
            "/content/drive/MyDrive/ai-intensive2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q1yezSmCRb2"
      },
      "source": [
        "# Lab 2 : Language Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VQwmHeYCRb6"
      },
      "source": [
        "@copyright:\n",
        "    (c) 2023. iKnow Lab. Ajou Univ., All rights reserved.\n",
        "\n",
        "M.S. Student: Wansik-Jo (jws5327@ajou.ac.kr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVnYghQ4CRb7"
      },
      "source": [
        "# For assignment\n",
        "\n",
        "- Python code의 주석 처리되어있는 부분을 구현하면 됩니다.\n",
        "- MD 형식의 Cell의 [BLANK] 부분을 채우면 됩니다.\n",
        "- MD 형식의 Cell의 [ANSWER] 부분 이후에 답을 작성하면 됩니다.\n",
        "- 조교에게 퀴즈의 답과 함께 코드 실행 결과를 보여준 뒤, BB에 제출 후 가시면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRJJ9nJ9CRb7"
      },
      "source": [
        "\n",
        "# 목차\n",
        "1. [Language Modeling](##1.-Language-Modeling)\n",
        "2. [N-gram Language Model](##2.-N-gram-Language-Model)\n",
        "3. [Perplexity](##3.-Perplexity)\n",
        "4. [Generalization](##4.-Generalization)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOramXoMCRb8"
      },
      "source": [
        "## 1. Language Modeling\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0MJRg7lCRb8"
      },
      "source": [
        "### 1.1. Language Modeling\n",
        "\n",
        "- 언어 모델링(Language Modeling)은 주어진 단어들의 나열에 대해 그 확률을 예측하는 작업이다.\n",
        "\n",
        "- 언어 모델은 다음과 같은 다양한 분야에서 활용된다.\n",
        "\n",
        "  - 기계 번역(Machine Translation)\n",
        "  - 오타 교정(Spell Correction)\n",
        "  - 음성 인식(Speech Recognition)\n",
        "  - 문장 자동 완성(Sentence Completion)\n",
        "  - 문장 유사도(Sentence Similarity)\n",
        "  - 감성 분석(Sentiment Analysis)\n",
        "  - 질의 응답(Question Answering)\n",
        "  - 챗봇(Chatbot)\n",
        "\n",
        "- 언어 모델링은 다음과 같은 다양한 방법으로 수행된다.\n",
        "\n",
        "    - N-gram Language Model\n",
        "    - Neural Network Language Model\n",
        "    - Transformer Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHsPsJr_CRb9"
      },
      "source": [
        "### 1.2 Markov Assumption\n",
        "\n",
        "- 언어 모델링은 다음과 같은 Markov Assumption을 기반으로 한다.\n",
        "\n",
        "    - 어떤 단어의 확률은 그 이전 단어들에만 의존한다.\n",
        "\n",
        "\n",
        "- 예를 들어, 다음 확률을 계산하고자 한다고 하자.\n",
        "\n",
        "$$ P(w_1, w_2, \\cdots, w_n) $$\n",
        "\n",
        "- 조건부 확률에 의해,\n",
        "\n",
        "$$ \\Pi_{i=1}^{n} P(w_i | w_1, w_2, \\cdots, w_{i-1}) $$\n",
        "\n",
        "- Chain Rule에 의해,\n",
        "\n",
        "$$ P(w_1, w_2, \\cdots, w_n) = P(w_1) P(w_2 | w_1) P(w_3 | w_1, w_2) \\cdots P(w_n | w_1, w_2, \\cdots, w_{n-1}) $$\n",
        "\n",
        "! 이는 모든 단어의 확률을 계산하기 위해 모든 이전 단어들을 고려해야 한다는 것을 의미한다. -> 비현실적\n",
        "\n",
        "- 따라서, Markov Assumption을 적용하면,\n",
        "\n",
        "$$ P(w_1, w_2, \\cdots, w_n) = \\Pi_{i=1}^{n} P(w_i | w_1, w_2, \\cdots, w_{i-1}) \\approx \\Pi_{i=1}^{n} P(w_i | w_{i-1}) $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEGxur-TCRb9"
      },
      "source": [
        "## 2. N-gram Language Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "no2QCIeiCRb-",
        "outputId": "82ccc8e2-b5aa-49ec-8403-332f27814633",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<s>', 'i'],\n",
              " ['i', 'do'],\n",
              " ['do', 'not'],\n",
              " ['not', 'like'],\n",
              " ['like', 'green'],\n",
              " ['green', 'eggs'],\n",
              " ['eggs', 'and'],\n",
              " ['and', 'ham'],\n",
              " ['ham', '</s>']]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "def sentence_to_ngrams(sentence, n):\n",
        "    \"\"\"\n",
        "    Converts a sentence into a list of n-grams.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    sentence : str\n",
        "        The sentence to convert.\n",
        "    n : int\n",
        "        The length of the n-grams.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        The list of n-grams.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    sentence = \"<s> \" + sentence + \" </s>\"\n",
        "    sentence = sentence.lower()\n",
        "    sentence = sentence.split()\n",
        "\n",
        "    ngrams = []\n",
        "    for i in range(len(sentence)-n+1):\n",
        "        ngrams.append(sentence[i:i+n])\n",
        "    return ngrams\n",
        "\n",
        "sentence_to_ngrams(\"I do not like green eggs and ham\", 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SOaeKLKYCRcA",
        "outputId": "75298571-311a-45f9-bc5a-2d8bb7175435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('<s>', 'i', 'do'): 2,\n",
              " ('i', 'do', 'not'): 2,\n",
              " ('do', 'not', 'like'): 2,\n",
              " ('not', 'like', 'green'): 1,\n",
              " ('like', 'green', 'eggs'): 1,\n",
              " ('green', 'eggs', 'and'): 1,\n",
              " ('eggs', 'and', 'ham'): 1,\n",
              " ('and', 'ham', '</s>'): 1,\n",
              " ('not', 'like', 'them'): 1,\n",
              " ('like', 'them', 'sam'): 1,\n",
              " ('them', 'sam', 'i'): 1,\n",
              " ('sam', 'i', 'am'): 1,\n",
              " ('i', 'am', '</s>'): 1}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# n-gram LM\n",
        "\n",
        "def ngram_LM(n, train_data):\n",
        "    \"\"\"\n",
        "    Builds an n-gram language model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n : int\n",
        "        The length of the n-grams.\n",
        "    train_data : list\n",
        "        The training data.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        The n-gram language model.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    ngram_lm = {}\n",
        "    for sentence in train_data:\n",
        "        ngrams = sentence_to_ngrams(sentence, n)\n",
        "        for ngram in ngrams:\n",
        "            ngram = tuple(ngram)\n",
        "            if ngram not in ngram_lm:\n",
        "                ngram_lm[ngram] = 1\n",
        "            else:\n",
        "                ngram_lm[ngram] += 1\n",
        "    return ngram_lm\n",
        "\n",
        "ngram_LM(3, [\"I do not like green eggs and ham\", \"I do not like them Sam I am\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VMyb-ygVCRcB",
        "outputId": "a499cd47-0dad-4e9e-8e8a-14622941fa0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.125"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "def ngram_prob(ngram, ngram_lm):\n",
        "    \"\"\"\n",
        "    Calculates the probability of an n-gram.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ngram : tuple\n",
        "        The n-gram.\n",
        "    ngram_lm : dict\n",
        "        The n-gram language model.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        The probability of the n-gram.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    ngram = tuple(ngram)\n",
        "    ngram_prob = ngram_lm[ngram] / sum(ngram_lm.values())\n",
        "    return ngram_prob\n",
        "\n",
        "ngram_prob((\"i\", \"do\", \"not\"), ngram_LM(3, [\"I do not like green eggs and ham\", \"I do not like them Sam I am\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsaze3uTCRcC"
      },
      "source": [
        "## 3. Perplexity\n",
        "\n",
        "$$ PP(W) = P(w_1, w_2, \\cdots, w_n)^{-\\frac{1}{n}} = \\sqrt[n]{\\frac{1}{P(w_1, w_2, \\cdots, w_n)}} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PGUdW_-wCRcC",
        "outputId": "d2536214-4ef9-475f-fa92-57b9a09f3416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.337686603263526"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#perplexity\n",
        "\n",
        "def perplexity(sentence, n, ngram_lm):\n",
        "    \"\"\"\n",
        "    Calculates the perplexity of a sentence.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    sentence : str\n",
        "        The sentence.\n",
        "    n : int\n",
        "        The length of the n-grams.\n",
        "    ngram_lm : dict\n",
        "        The n-gram language model.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        The perplexity of the sentence.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    ngrams = sentence_to_ngrams(sentence, n)\n",
        "    perplexity = 1\n",
        "    for ngram in ngrams:\n",
        "        perplexity *= 1/ngram_prob(ngram, ngram_lm)\n",
        "    perplexity = perplexity**(1/len(ngrams))\n",
        "    return perplexity\n",
        "\n",
        "perplexity(\"I do not like green eggs and ham\", 3, ngram_LM(3, [\"I do not like green eggs and ham\", \"I do not like them Sam I am\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgWQXqeaCRcC"
      },
      "source": [
        "## 4. Generalization\n",
        "\n",
        "!What is the problem of N-gram Language Model?\n",
        "\n",
        "[ANSWER] : 한번도 등장하지 않았을 경우 0으로 나누는 꼴이 돼서 문제가 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Cl5miWyCRcC"
      },
      "source": [
        "**Laplace** Smoothing\n",
        "\n",
        "$$ P_{Laplace}(w_i | w_{i-1}) = \\frac{C(w_{i-1}, w_i) + 1}{C(w_{i-1}) + V} $$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ngram_prob_cond(prior, token, n, data):\n",
        "    ngram_lm = ngram_LM(n, data)\n",
        "    npgram_lm = ngram_LM(n + 1, data)\n",
        "\n",
        "    npgram = (*prior, token)\n",
        "    prob = (npgram_lm[npgram] + 1) / (ngram_lm[prior] + len(ngram_lm))\n",
        "    return prob\n",
        "\n",
        "\n",
        "ngram_prob_cond(\n",
        "    (\"do\", \"not\", \"like\"),\n",
        "    'green',\n",
        "    3,\n",
        "    ['I do not like green eggs and ham', 'I do not like then Sam I am']\n",
        ")"
      ],
      "metadata": {
        "id": "yBgQu69KEdfb",
        "outputId": "655bfc80-2520-4da6-cc50-d062271638fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-L_TX9SkL71_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cpwan",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}