{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 : Naive Bayes Classifier for Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@copyright: \n",
    "    (c) 2023. iKnow Lab. Ajou Univ., All rights reserved.\n",
    "\n",
    "M.S. Student: Wansik-Jo (jws5327@ajou.ac.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For assignment\n",
    "\n",
    "- Python code의 주석 처리되어있는 부분을 구현하면 됩니다.\n",
    "- MD 형식의 Cell의 [BLANK] 부분을 채우면 됩니다.\n",
    "- MD 형식의 Cell의 [ANSWER] 부분 이후에 답을 작성하면 됩니다.\n",
    "- 조교에게 퀴즈의 답과 함께 코드 실행 결과를 보여준 뒤, BB에 제출 후 가시면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 목차\n",
    "1. Document Classification task 이해하기\n",
    "    - Dataset 살펴보기\n",
    "    - Task 이해하기\n",
    "2. Data Preprocessing \n",
    "    - Dataloader 구현하기\n",
    "    - Data 확인하기\n",
    "    - Data preprocessing 구현하기\n",
    "3. Naive Bayes Classifier 구현하기\n",
    "    - 수식 이해하기\n",
    "    - Vocabulary 구축하기\n",
    "    - Prior 계산하기\n",
    "    - Likelihood 계산하기\n",
    "    - Posterior 계산하기\n",
    "    - Prediction 구하기\n",
    "    - Model 학습하기\n",
    "    - Model 성능 평가하기\n",
    "4. Naive Bayes Classifier의 여러 변형 모델 응용하기\n",
    "    - 과제\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document Classification task 이해하기\n",
    "- Dataset: NewsGroup Documents datasets\n",
    "- Task: Document Classification\n",
    "- Input: Document\n",
    "- Output: Document Category\n",
    "- Model: Naive Bayes Classifier\n",
    "- Evaluation: Confusion Matrix, Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Classification dataset\n",
    "\n",
    "- URL : https://www.kaggle.com/datasets/jensenbaxter/10dataset-text-document-classification\n",
    "\n",
    "- Kaggle 10 group dataset\n",
    "- 각 Document는, 10개의 category 중 하나에 속함\n",
    "- Categories : business, entertainment, food, graphics, historical, medical, politics, space, sport, technologie\n",
    "- URL 또는 강의노트에서 제공되는 data를 받아서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 200\n"
     ]
    }
   ],
   "source": [
    "#dataset load\n",
    "categories = {'business', 'entertainment', 'food', 'graphics', 'historical', 'medical', 'politics', 'space', 'sport', 'technologie'}\n",
    "\n",
    "import os\n",
    "\n",
    "dataset = []\n",
    "for category in categories:\n",
    "    for filename in os.listdir('data/' + category):\n",
    "        with open('data/' + category + '/' + filename, 'r') as f:\n",
    "            instance = {}\n",
    "            instance['text'] = f.read()\n",
    "            instance['category'] = category\n",
    "            dataset.append(instance)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(dataset)\n",
    "train_data = dataset[:int(len(dataset) * 0.8)]\n",
    "test_data = dataset[int(len(dataset) * 0.8):]\n",
    "\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brewers' profits lose their fizz\n",
      "\n",
      "Heineken and Carlsberg, two of the world's largest brewers, have reported falling profits after beer sales in western Europe fell flat.\n",
      "\n",
      "Dutch firm Heineken saw its annual profits drop 33% and warned that earnings in 2005 may also slide. Danish brewer Carlsberg suffered a 3% fall in profits due to waning demand and increased marketing costs. Both are looking to Russia and China to provide future growth as western European markets are largely mature.\n",
      "\n",
      "Heineken's net income fell to 537m euros ($701m; £371m) during 2004, from 798m euro a year ago. It blamed weak demand in western Europe and currency losses. It had warned in September that the weakening US dollar, which has cut the value of foreign sales, would knock 125m euros off its operating profits. Despite the dip in profits, Heineken's sales have been improving and total revenue for the year was 10bn euros, up 8.1% from 9.26bn euros in 2003. Heineken said it now plans to invest 100m euros in \"aggressive\" and \"high-impact\" marketing in Europe and the US in 2005. Heineken, which also owns the Amstel and Murphy's stout brands, said it would also seek to cut costs. This may involve closing down breweries.\n",
      "\n",
      "Heineken increased its dividend payment by 25% to 40 euro cents, but warned that the continued impact of a weaker dollar and an increased marketing spend may lead to a drop in 2005 net profit.\n",
      "\n",
      "Carlsberg, the world's fifth-largest brewer, saw annual pre-tax profits fall to 3.4bn Danish kroner (456m euros). Its beer sales have been affected by the sluggish European economy and by the banning of smoking in pubs in several European countries. Nevertheless, total sales increased 4% to 36bn kroner, thanks to strong sales of Carlsberg lager in Russia and Poland. Carlsberg is more optimistic than Heineken about 2005, projecting a 15% rise in net profits for the year. However, it also plans to cut 200 jobs in Sweden, where sales have been hit by demand for cheap, imported brands. \"We remain cautious about the medium-to-long term outlook for revenue growth across western Europe for a host of economic, social and structural reasons,\" investment bank Merrill Lynch said of Carlsberg.\n",
      "\n",
      "business\n",
      "Counter({'historical': 87, 'graphics': 83, 'food': 83, 'politics': 83, 'entertainment': 83, 'sport': 78, 'technologie': 77, 'space': 76, 'business': 75, 'medical': 75})\n"
     ]
    }
   ],
   "source": [
    "#data 확인\n",
    "print(train_data[0]['text'])\n",
    "print(train_data[0]['category'])\n",
    "\n",
    "#label 비율 확인\n",
    "from collections import Counter\n",
    "print(Counter([instance['category'] for instance in train_data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document raw data preprocessing\n",
    "\n",
    "- 학습한 여러 기법을 활용하여 데이터 전처리를 진행\n",
    "- Tokenizing, Stemming, Lemmatizing, Stopword 제거, Punctuation 제거, Case 변환 등 다양한 NLP pre processing 방법을 적용\n",
    "- News data에 맞는 e-mail, url, phone number, number, date, time 등의 특수문자 제거 (Regex)\n",
    "\n",
    "- !nltk library 만 사용 가능 (import nltk)\n",
    "- !단 e-mail, url, phone number, number, date, time 등에 관한 처리는 regex를 사용하여 직접 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "#You can use pre-defined tools in nltk, like Tokenizer, Stopword list, etc.\n",
    "\n",
    "for instance in train_data:\n",
    "    #You should implement any pre-processing if you need.\n",
    "    text = instance['text'].lower()\n",
    "\n",
    "    #Or like here, you can use regular expression to remove any unwanted characters.\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    \"\"\"\n",
    "    From here, you should implement any pre-process method like tokenizer, stopword list, stemming, lemmatization, etc.\n",
    "    Or the regular expression above can be considered.\n",
    "\n",
    "    text = \n",
    "    \n",
    "    \"\"\"\n",
    "    instance['tokens'] = text\n",
    "\n",
    "for instance in test_data:\n",
    "    #And also for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brewers' profits lose their fizz\n",
      "\n",
      "Heineken and Carlsberg, two of the world's largest brewers, have reported falling profits after beer sales in western Europe fell flat.\n",
      "\n",
      "Dutch firm Heineken saw its annual profits drop 33% and warned that earnings in 2005 may also slide. Danish brewer Carlsberg suffered a 3% fall in profits due to waning demand and increased marketing costs. Both are looking to Russia and China to provide future growth as western European markets are largely mature.\n",
      "\n",
      "Heineken's net income fell to 537m euros ($701m; £371m) during 2004, from 798m euro a year ago. It blamed weak demand in western Europe and currency losses. It had warned in September that the weakening US dollar, which has cut the value of foreign sales, would knock 125m euros off its operating profits. Despite the dip in profits, Heineken's sales have been improving and total revenue for the year was 10bn euros, up 8.1% from 9.26bn euros in 2003. Heineken said it now plans to invest 100m euros in \"aggressive\" and \"high-impact\" marketing in Europe and the US in 2005. Heineken, which also owns the Amstel and Murphy's stout brands, said it would also seek to cut costs. This may involve closing down breweries.\n",
      "\n",
      "Heineken increased its dividend payment by 25% to 40 euro cents, but warned that the continued impact of a weaker dollar and an increased marketing spend may lead to a drop in 2005 net profit.\n",
      "\n",
      "Carlsberg, the world's fifth-largest brewer, saw annual pre-tax profits fall to 3.4bn Danish kroner (456m euros). Its beer sales have been affected by the sluggish European economy and by the banning of smoking in pubs in several European countries. Nevertheless, total sales increased 4% to 36bn kroner, thanks to strong sales of Carlsberg lager in Russia and Poland. Carlsberg is more optimistic than Heineken about 2005, projecting a 15% rise in net profits for the year. However, it also plans to cut 200 jobs in Sweden, where sales have been hit by demand for cheap, imported brands. \"We remain cautious about the medium-to-long term outlook for revenue growth across western Europe for a host of economic, social and structural reasons,\" investment bank Merrill Lynch said of Carlsberg.\n",
      "\n",
      "['brewer', 'profit', 'lose', 'fizz', 'heineken', 'carlsberg', 'two', 'world', 'largest', 'brewer', 'report', 'fall', 'profit', 'beer', 'sale', 'western', 'europ', 'fell', 'flat', 'dutch', 'firm', 'heineken', 'saw', 'annual', 'profit', 'drop', 'warn', 'earn', 'may', 'also', 'slide', 'danish', 'brewer', 'carlsberg', 'suffer', 'fall', 'profit', 'due', 'wane', 'demand', 'increas', 'market', 'cost', 'look', 'russia', 'china', 'provid', 'futur', 'growth', 'western', 'european', 'market', 'larg', 'matur', 'heineken', 'net', 'incom', 'fell', 'euro', 'euro', 'year', 'ago', 'blame', 'weak', 'demand', 'western', 'europ', 'currenc', 'loss', 'warn', 'septemb', 'weaken', 'u', 'dollar', 'cut', 'valu', 'foreign', 'sale', 'would', 'knock', 'euro', 'oper', 'profit', 'despit', 'dip', 'profit', 'heineken', 'sale', 'improv', 'total', 'revenu', 'year', 'bn', 'euro', 'bn', 'euro', 'heineken', 'said', 'plan', 'invest', 'euro', 'aggress', 'highimpact', 'market', 'europ', 'u', 'heineken', 'also', 'own', 'amstel', 'murphi', 'stout', 'brand', 'said', 'would', 'also', 'seek', 'cut', 'cost', 'may', 'involv', 'close', 'breweri', 'heineken', 'increas', 'dividend', 'payment', 'euro', 'cent', 'warn', 'continu', 'impact', 'weaker', 'dollar', 'increas', 'market', 'spend', 'may', 'lead', 'drop', 'net', 'profit', 'carlsberg', 'world', 'fifthlargest', 'brewer', 'saw', 'annual', 'pretax', 'profit', 'fall', 'bn', 'danish', 'krone', 'euro', 'beer', 'sale', 'affect', 'sluggish', 'european', 'economi', 'ban', 'smoke', 'pub', 'sever', 'european', 'countri', 'nevertheless', 'total', 'sale', 'increas', 'bn', 'krone', 'thank', 'strong', 'sale', 'carlsberg', 'lager', 'russia', 'poland', 'carlsberg', 'optimist', 'heineken', 'project', 'rise', 'net', 'profit', 'year', 'howev', 'also', 'plan', 'cut', 'job', 'sweden', 'sale', 'hit', 'demand', 'cheap', 'import', 'brand', 'remain', 'cautiou', 'mediumtolong', 'term', 'outlook', 'revenu', 'growth', 'across', 'western', 'europ', 'host', 'econom', 'social', 'structur', 'reason', 'invest', 'bank', 'merril', 'lynch', 'said', 'carlsberg']\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "print(train_data[0]['text'])\n",
    "print(train_data[0]['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naive Bayes Classifier 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes to Documents and Categories\n",
    "\n",
    "document $d$ 와 category $c$ 에 대하여, posterior probability는 다음과 같이 구할 수 있다.\n",
    "\n",
    "$$ P(c|d) = \\frac{P(d|c)P(c)}{P(d)} $$\n",
    "\n",
    "이때 $P(c)$ 를 category $c$ 의[BLANK],\n",
    "\n",
    "$P(d|c)$ 를 category $c$ 에서 document $d$ 의 [BLANK],\n",
    "\n",
    "$P(d)$ 를 document $d$ 의 [BLANK] 라고 한다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "\n",
    "이 때, MAP(most probable category) $c_{MAP}$ for a document $d$ 는 다음과 같이 구할 수 있다.\n",
    "\n",
    "$$ C_{MAP} = \\underset{c \\in C}{\\operatorname{argmax}} P(c|d) $$\n",
    "\n",
    "그러나, $P(c|d)$ 를 직접 계산하기는 어렵다. ($P(d)$ 를 계산하기 어렵기 때문에)\n",
    "\n",
    "따라서, 여기서 Bayes' theorem 을 사용하여 $P(c|d)$ 를 다음과 같이 바꿀 수 있다.\n",
    "\n",
    "$$ P(c|d) = \\frac{P(d|c)P(c)}{P(d)} $$\n",
    "\n",
    "</br>\n",
    "\n",
    "이때, $P(d)$ 는 모든 category $c$ 에 대하여 동일하므로, $P(d)$ 는 상수이다. (계산할 필요가 없다.)\n",
    "\n",
    "따라서,\n",
    "\n",
    "$$ C_{MAP} = \\underset{c \\in C}{\\operatorname{argmax}} P(d|c)P(c) $$\n",
    "\n",
    "이때, $P(d|c)$ 를 [BLANK], $P(c)$ 를 [BLANK] 라고 한다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier\n",
    "\n",
    "likelihood $P(d|c)$ 는 다음과 같이 계산할 수 있다.\n",
    "\n",
    "$$ P(d|c) = P(w_1, w_2, \\cdots, w_n|c) = \\prod_{i=1}^{n} P(w_i|c) $$\n",
    "\n",
    "이때 $w_i$ 는 $i$-th 번째 word in document $d$ 이다.\n",
    "\n",
    "따라서, 최종 식은 다음과 같다.\n",
    "\n",
    "$$ C_{NB} = \\underset{c \\in C}{\\operatorname{argmax}} P(c) \\prod_{i=1}^{n} P(w_i|c) $$\n",
    "\n",
    "! 여기서 발생할 수 있는 문제점은?\n",
    "\n",
    "[ANSWER] :\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Likelihood\n",
    "\n",
    "문제는 likelihood $P(d|c)$ 가 매우 작은 값이 될 수 있다는 것이다.\n",
    "\n",
    "따라서, likelihood 대신 log likelihood 를 사용하면 다음과 같다.\n",
    "\n",
    "$$ C_{NB} = \\underset{c \\in C}{\\operatorname{argmax}} P(c) \\sum_{i=1}^{n} \\log P(w_i|c) $$\n",
    "\n",
    "! 여기서 발생할 수 있는 문제점은?\n",
    "\n",
    "[ANSWER] :\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace smoothing\n",
    "\n",
    "문제는 likelihood $P(d|c)$ 가 0이 될 수 있다는 것이다.\n",
    "\n",
    "따라서 zero0-probability 를 방지하기 위하여 Laplace smoothing 을 사용한다.\n",
    "\n",
    "$$ P(w_i|c) = \\frac{count(w_i, c) + \\alpha}{count(c) + \\alpha \\times |V|} $$\n",
    "\n",
    "이때, $count(w_i, c)$ 는 category $c$ 에서 $w_i$ 의 개수이고\n",
    "\n",
    "$count(c)$ 는 category $c$ 에서 word 의 총 개수,\n",
    "\n",
    "$|V|$ 는 vocabulary 의 길이.\n",
    "\n",
    "$\\alpha$ 는 smoothing parameter 이다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sport', 'entertainment', 'space', 'politics', 'historical', 'graphics', 'technologie', 'business', 'food', 'medical'}\n",
      "18717\n"
     ]
    }
   ],
   "source": [
    "#make vocabulary\n",
    "vocabulary = set()\n",
    "for instance in train_data:\n",
    "    vocabulary.update(instance['tokens'])\n",
    "\n",
    "print(categories)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "def train_classifier(data, categories, vocabulary):\n",
    "    prior = {category: 0 for category in categories}\n",
    "    likelihood = defaultdict(lambda: defaultdict(int))\n",
    "    category_counts = {category: 0 for category in categories} # Initialize category_counts to track total tokens per category\n",
    "\n",
    "    #You should implement the training process of Naive Bayes classifier.\n",
    "\n",
    "    for instance in data:\n",
    "        for token in instance['tokens']:\n",
    "            \"\"\"\n",
    "            Here, you should calculate the prior and likelihood.\n",
    "            \n",
    "            \"\"\"\n",
    "\n",
    "    total_instances = len(data)\n",
    "    for category in categories:\n",
    "        \"\"\" \n",
    "        Here, calculate the prior and likelihood, for each category.\n",
    "        Like we have learned above, you should use Log-likelihood, and Laplace smoothing.\n",
    "        \n",
    "        prior[category] =\n",
    "        for word in vocabulary:\n",
    "            likelihood[category][word] =\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    return prior, likelihood, category_counts\n",
    "\n",
    "prior, likelihood, category_counts = train_classifier(train_data, categories, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical\n"
     ]
    }
   ],
   "source": [
    "def predict(instance, prior, likelihood, categories, category_counts, vocabulary):\n",
    "    score = {}\n",
    "\n",
    "    #You should implement the prediction process of Naive Bayes classifier.\n",
    "\n",
    "    for category in categories:\n",
    "        \"\"\"\n",
    "        Here, you should calculate the score of each category.\n",
    "        score[category] = prior[category]\n",
    "        for token in instance['tokens']:\n",
    "            score[catetory] += \n",
    "            You should consider the case when the token is unseen here.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    return max(score, key=score.get)\n",
    "\n",
    "print(predict(test_data[0], prior, likelihood, categories, category_counts, vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97 {'sport': 1.0, 'entertainment': 1.0, 'space': 1.0, 'politics': 0.8421052631578947, 'historical': 0.9285714285714286, 'graphics': 1.0, 'technologie': 1.0, 'business': 1.0, 'food': 0.9411764705882353, 'medical': 0.9615384615384616} {'sport': 1.0, 'entertainment': 1.0, 'space': 0.9166666666666666, 'politics': 0.9411764705882353, 'historical': 1.0, 'graphics': 1.0, 'technologie': 1.0, 'business': 0.92, 'food': 0.9411764705882353, 'medical': 1.0}\n"
     ]
    }
   ],
   "source": [
    "def evaluate(data, prior, likelihood, categories, category_counts, vocabulary):\n",
    "    metrics = {\n",
    "        'TP': {category: 0 for category in categories},\n",
    "        'TN': {category: 0 for category in categories},\n",
    "        'FP': {category: 0 for category in categories},\n",
    "        'FN': {category: 0 for category in categories},\n",
    "    }\n",
    "\n",
    "    #You should implement confusion matrix here. Fill in if statement below.\n",
    "    for instance in data:\n",
    "        true_category = instance['category']\n",
    "        predicted_category = predict(instance, prior, likelihood, categories, category_counts, vocabulary)\n",
    "        \n",
    "        for category in categories:\n",
    "            if :\n",
    "                metrics['TP'][category] += 1\n",
    "            if :\n",
    "                metrics['TN'][category] += 1\n",
    "            if :\n",
    "                metrics['FP'][category] += 1\n",
    "            if :\n",
    "                metrics['FN'][category] += 1\n",
    "\n",
    "    precision = {category: metrics['TP'][category] / (metrics['TP'][category] + metrics['FP'][category]) for category in categories}\n",
    "    recall = {category: metrics['TP'][category] / (metrics['TP'][category] + metrics['FN'][category]) for category in categories}\n",
    "    accuracy = sum(metrics['TP'].values()) / len(data)\n",
    "    \n",
    "    return accuracy, precision, recall\n",
    "\n",
    "accuracy, precision, recall = evaluate(test_data, prior, likelihood, categories, category_counts, vocabulary)\n",
    "print(accuracy, precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Naive Bayes Classifier의 여러 변형 모델 응용하기\n",
    "\n",
    "- N-gram을 활용한 Naive Bayes Classifier (과제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpwan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
